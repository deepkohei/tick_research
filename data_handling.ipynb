{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "# N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = '/home/m2021ksugawara/work/tick_research'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量を板の基本情報（気配値から１０レベル以内のask,ask_vol,bid,bid_volの４つのグラフ）のみに絞る関数\n",
    "def prepare_x(data):\n",
    "    df1 = data[:40, :].T\n",
    "    return np.array(df1)\n",
    "\n",
    "#labelを取得（５つある理由は\n",
    "def get_label(data):\n",
    "    lob = data[-5:, :].T\n",
    "    return lob\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape  #N=n,D=40\n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]   #入力データとして直近100の状態を使うので、ラベルデータの最初のT-1(=99)個は不要。具体的にはevent time100における予測を行うには1~100の時刻の状態を入力として時刻100のラベルを使うから\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))  #(サンプル数,直近100時刻前までの状態=100,特徴量次元=40)\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX, dataY   #dataX.shape=(サンプル数=N-100,直近の状態=100,各時刻の特徴量次元=40),dataY.shape=(サンプル数=N-100,ラベル次元=5)\n",
    "\n",
    "def torch_data(x, y):\n",
    "    x = torch.from_numpy(x)\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = F.one_hot(y, num_classes=3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, data, k, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        x = prepare_x(data)  #特徴量の取得：(n,40)\n",
    "        y = get_label(data)  #ラベルの取得：(n,5)\n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        y = y[:,self.k] - 1  #4step先の仲値の平均値を使用して算出したラベル値を採用することを意味している。-1しているのは0,1,2にしている。（なぜ？）\n",
    "        self.length = len(x)\n",
    "#         print(f'{y.shape} in dataset')\n",
    "#         print(y)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "dataの特徴：\n",
    "training dataのファイル名の数字はi番目のデータセット(fold)であることを意味してるが、これは1日目〜i日目までのデータが含まれていることを意味している。一方でtest dataの場合、数字iが含まれているファイルはi+1日目のデータが含まれていることを意味している。\n",
    "<span style=\"color: red; \">\n",
    "    ここは注意。test dataは一日目のデータがないのでファイル名に1が入っているファイルの中身は2日目のデータ。\n",
    "</span>\n",
    "DeepLOBの論文では以下の２つのSetUpで実験している。<br>\n",
    "①：1日目〜i日目までのデータをトレーニングデータとして使い、i+1日目までのデータをテストデータとして使う。これをi=1~9で試す(交差検証)\n",
    "<br>\n",
    "➁：1日目〜7日目までのデータをトレーニングデータとして使い、8〜10日目までのデータをテストデータとして使う。\n",
    "<br>\n",
    "以下では➁のパターンの再現をしている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 59973)\n",
      "(149, 242360) (149, 60591) (149, 155174)\n"
     ]
    }
   ],
   "source": [
    "# please change the data_path to your local path\n",
    "# data_path = '/nfs/home/zihaoz/limit_order_book/data'\n",
    "data_path = f'{HOME}/published/BenchmarkDatasets/BenchmarkDatasets'\n",
    "\n",
    "dec_data = np.loadtxt(f'{data_path}/Auction/1.Auction_Zscore/Auction_Zscore_Training/Train_Dst_Auction_ZScore_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "dec_test1 = np.loadtxt(f'{data_path}/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_7.txt')\n",
    "dec_test2 = np.loadtxt(f'{data_path}/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_8.txt')\n",
    "dec_test3 = np.loadtxt(f'{data_path}/Auction/1.Auction_Zscore/Auction_Zscore_Testing/Test_Dst_Auction_ZScore_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "print(dec_test1.shape)\n",
    "\n",
    "print(dec_train.shape, dec_val.shape, dec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([242261, 1, 100, 40]) torch.Size([242261])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "#下のT=100は入力のxとして直近100の状態を使うということを意味している。\n",
    "#k=4はlabelを作成するときに現在時刻からk(=4)step先の状態までの仲値の平均としきい値を比較して上昇、下降、変化なしを決定している値を撮ってきていることを意味している。\n",
    "#つまりこのモデルは過去T=100step前までのデータを用いてk=4step先にかけての変動を予測するものになるということ？4step先で意味あるのか？\n",
    "#num_classes=3は「上昇」「下降」「変化なし」の３つのクラスでラベリングしていることを表している。\n",
    "dataset_train = Dataset(data=dec_train, k=4, num_classes=3, T=100)\n",
    "dataset_val = Dataset(data=dec_val, k=4, num_classes=3, T=100)\n",
    "dataset_test = Dataset(data=dec_test, k=4, num_classes=3, T=100)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(dataset_train.x.shape, dataset_train.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.0257,  0.8198, -1.0251,  ..., -0.3117, -1.0240, -0.3237],\n",
      "          [-1.0257,  1.9649, -1.0261,  ..., -0.3117, -1.0250,  1.8370],\n",
      "          [-1.0257,  1.9649, -1.0251,  ..., -0.3117, -1.0240, -0.3237],\n",
      "          ...,\n",
      "          [-1.0247, -0.6698, -1.0251,  ..., -0.3117, -1.0240, -0.3237],\n",
      "          [-1.0247, -0.6698, -1.0251,  ..., -0.3117, -1.0240, -0.3237],\n",
      "          [-1.0247,  0.5497, -1.0251,  ..., -0.3117, -1.0240, -0.3237]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "torch.Size([1, 1, 100, 40]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(64, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m2021ksugawara/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "deeplob                                  --                        --\n",
       "├─Sequential: 1-1                        [1, 32, 94, 20]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 100, 20]          96\n",
       "│    └─LeakyReLU: 2-2                    [1, 32, 100, 20]          --\n",
       "│    └─BatchNorm2d: 2-3                  [1, 32, 100, 20]          64\n",
       "│    └─Conv2d: 2-4                       [1, 32, 97, 20]           4,128\n",
       "│    └─LeakyReLU: 2-5                    [1, 32, 97, 20]           --\n",
       "│    └─BatchNorm2d: 2-6                  [1, 32, 97, 20]           64\n",
       "│    └─Conv2d: 2-7                       [1, 32, 94, 20]           4,128\n",
       "│    └─LeakyReLU: 2-8                    [1, 32, 94, 20]           --\n",
       "│    └─BatchNorm2d: 2-9                  [1, 32, 94, 20]           64\n",
       "├─Sequential: 1-2                        [1, 32, 88, 10]           --\n",
       "│    └─Conv2d: 2-10                      [1, 32, 94, 10]           2,080\n",
       "│    └─Tanh: 2-11                        [1, 32, 94, 10]           --\n",
       "│    └─BatchNorm2d: 2-12                 [1, 32, 94, 10]           64\n",
       "│    └─Conv2d: 2-13                      [1, 32, 91, 10]           4,128\n",
       "│    └─Tanh: 2-14                        [1, 32, 91, 10]           --\n",
       "│    └─BatchNorm2d: 2-15                 [1, 32, 91, 10]           64\n",
       "│    └─Conv2d: 2-16                      [1, 32, 88, 10]           4,128\n",
       "│    └─Tanh: 2-17                        [1, 32, 88, 10]           --\n",
       "│    └─BatchNorm2d: 2-18                 [1, 32, 88, 10]           64\n",
       "├─Sequential: 1-3                        [1, 32, 82, 1]            --\n",
       "│    └─Conv2d: 2-19                      [1, 32, 88, 1]            10,272\n",
       "│    └─LeakyReLU: 2-20                   [1, 32, 88, 1]            --\n",
       "│    └─BatchNorm2d: 2-21                 [1, 32, 88, 1]            64\n",
       "│    └─Conv2d: 2-22                      [1, 32, 85, 1]            4,128\n",
       "│    └─LeakyReLU: 2-23                   [1, 32, 85, 1]            --\n",
       "│    └─BatchNorm2d: 2-24                 [1, 32, 85, 1]            64\n",
       "│    └─Conv2d: 2-25                      [1, 32, 82, 1]            4,128\n",
       "│    └─LeakyReLU: 2-26                   [1, 32, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-27                 [1, 32, 82, 1]            64\n",
       "├─Sequential: 1-4                        [1, 64, 82, 1]            --\n",
       "│    └─Conv2d: 2-28                      [1, 64, 82, 1]            2,112\n",
       "│    └─LeakyReLU: 2-29                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-30                 [1, 64, 82, 1]            128\n",
       "│    └─Conv2d: 2-31                      [1, 64, 82, 1]            12,352\n",
       "│    └─LeakyReLU: 2-32                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-33                 [1, 64, 82, 1]            128\n",
       "├─Sequential: 1-5                        [1, 64, 82, 1]            --\n",
       "│    └─Conv2d: 2-34                      [1, 64, 82, 1]            2,112\n",
       "│    └─LeakyReLU: 2-35                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-36                 [1, 64, 82, 1]            128\n",
       "│    └─Conv2d: 2-37                      [1, 64, 82, 1]            20,544\n",
       "│    └─LeakyReLU: 2-38                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-39                 [1, 64, 82, 1]            128\n",
       "├─Sequential: 1-6                        [1, 64, 82, 1]            --\n",
       "│    └─MaxPool2d: 2-40                   [1, 32, 82, 1]            --\n",
       "│    └─Conv2d: 2-41                      [1, 64, 82, 1]            2,112\n",
       "│    └─LeakyReLU: 2-42                   [1, 64, 82, 1]            --\n",
       "│    └─BatchNorm2d: 2-43                 [1, 64, 82, 1]            128\n",
       "├─LSTM: 1-7                              [1, 82, 64]               66,048\n",
       "├─Linear: 1-8                            [1, 3]                    195\n",
       "==========================================================================================\n",
       "Total params: 143,907\n",
       "Trainable params: 143,907\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 35.53\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 4.97\n",
       "Params size (MB): 0.58\n",
       "Estimated Total Size (MB): 5.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 1, 100, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to encapsulate the training loop\n",
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    best_test_loss = np.inf\n",
    "    best_test_epoch = 0\n",
    "\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "            # print(\"inputs.shape:\", inputs.shape)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            # print(\"about to get model output\")\n",
    "            outputs = model(inputs)\n",
    "            # print(\"done getting model output\")\n",
    "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward and optimize\n",
    "            # print(\"about to optimize\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            torch.save(model, './best_val_model_pytorch')\n",
    "            best_test_loss = test_loss\n",
    "            best_test_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                        | 1/50 [07:21<6:00:47, 441.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/50, Train Loss: 0.9103,           Validation Loss: 0.9444, Duration: 0:07:21.787293, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                       | 2/50 [14:44<5:54:01, 442.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 2/50, Train Loss: 0.8226,           Validation Loss: 0.9312, Duration: 0:07:23.052329, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                      | 3/50 [22:07<5:46:36, 442.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/50, Train Loss: 0.7959,           Validation Loss: 0.9103, Duration: 0:07:22.433505, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▎                                     | 4/50 [29:29<5:39:07, 442.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/50, Train Loss: 0.7771,           Validation Loss: 0.9089, Duration: 0:07:22.086881, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████                                     | 5/50 [36:51<5:31:44, 442.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 5/50, Train Loss: 0.7626,           Validation Loss: 0.8974, Duration: 0:07:22.317686, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▉                                    | 6/50 [44:14<5:24:22, 442.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 6/50, Train Loss: 0.7523,           Validation Loss: 0.8844, Duration: 0:07:22.349429, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▋                                   | 7/50 [51:36<5:17:03, 442.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 0.7435,           Validation Loss: 0.8998, Duration: 0:07:22.522116, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████▌                                  | 8/50 [58:58<5:09:41, 442.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 0.7353,           Validation Loss: 0.8891, Duration: 0:07:22.429166, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████                                | 9/50 [1:06:21<5:02:20, 442.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 0.7290,           Validation Loss: 0.8884, Duration: 0:07:22.515504, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████▌                              | 10/50 [1:13:43<4:54:56, 442.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 0.7228,           Validation Loss: 0.8904, Duration: 0:07:22.368417, Best Val Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|████████▎                             | 11/50 [1:21:06<4:47:31, 442.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 11/50, Train Loss: 0.7188,           Validation Loss: 0.8784, Duration: 0:07:22.200802, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|█████████                             | 12/50 [1:28:28<4:40:12, 442.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.7133,           Validation Loss: 0.8914, Duration: 0:07:22.617987, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████▉                            | 13/50 [1:35:51<4:32:50, 442.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 0.7093,           Validation Loss: 0.8847, Duration: 0:07:22.456982, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████▋                           | 14/50 [1:43:13<4:25:28, 442.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 0.7053,           Validation Loss: 0.8819, Duration: 0:07:22.498729, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████▍                          | 15/50 [1:50:36<4:18:07, 442.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.7016,           Validation Loss: 0.8811, Duration: 0:07:22.623094, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████▏                         | 16/50 [1:57:59<4:10:52, 442.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 0.6985,           Validation Loss: 0.8819, Duration: 0:07:23.177467, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████▉                         | 17/50 [2:05:22<4:03:35, 442.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 0.6952,           Validation Loss: 0.8981, Duration: 0:07:23.366553, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████▋                        | 18/50 [2:12:46<3:56:21, 443.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 0.6915,           Validation Loss: 0.8915, Duration: 0:07:23.772302, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████▍                       | 19/50 [2:20:10<3:49:05, 443.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 0.6897,           Validation Loss: 0.8879, Duration: 0:07:23.997120, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████▏                      | 20/50 [2:27:34<3:41:48, 443.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 0.6870,           Validation Loss: 0.8878, Duration: 0:07:24.048454, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████▉                      | 21/50 [2:34:58<3:34:31, 443.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 0.6850,           Validation Loss: 0.8945, Duration: 0:07:24.348757, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████▋                     | 22/50 [2:42:23<3:27:10, 443.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 0.6820,           Validation Loss: 0.8912, Duration: 0:07:24.163382, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████▍                    | 23/50 [2:49:47<3:19:51, 444.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 0.6801,           Validation Loss: 0.8924, Duration: 0:07:24.606543, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████▏                   | 24/50 [2:57:12<3:12:31, 444.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 0.6782,           Validation Loss: 0.8918, Duration: 0:07:24.606396, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████                   | 25/50 [3:04:37<3:05:11, 444.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 0.6770,           Validation Loss: 0.9012, Duration: 0:07:24.882089, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████▊                  | 26/50 [3:12:01<2:57:48, 444.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 0.6743,           Validation Loss: 0.8909, Duration: 0:07:24.616160, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████▌                 | 27/50 [3:19:26<2:50:25, 444.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 0.6730,           Validation Loss: 0.8882, Duration: 0:07:24.760291, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████▎                | 28/50 [3:26:51<2:43:02, 444.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 0.6716,           Validation Loss: 0.8975, Duration: 0:07:24.901926, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████                | 29/50 [3:34:16<2:35:39, 444.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 0.6700,           Validation Loss: 0.8963, Duration: 0:07:24.934993, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████▊               | 30/50 [3:41:41<2:28:16, 444.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 0.6684,           Validation Loss: 0.8882, Duration: 0:07:25.063099, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████▌              | 31/50 [3:49:06<2:20:54, 444.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 0.6669,           Validation Loss: 0.8912, Duration: 0:07:25.196939, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████▎             | 32/50 [3:56:31<2:13:30, 445.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 0.6661,           Validation Loss: 0.8946, Duration: 0:07:25.126458, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████             | 33/50 [4:03:56<2:06:04, 444.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 0.6649,           Validation Loss: 0.8994, Duration: 0:07:24.945240, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|█████████████████████████▊            | 34/50 [4:11:21<1:58:40, 445.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 0.6638,           Validation Loss: 0.8917, Duration: 0:07:25.169608, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████▌           | 35/50 [4:18:47<1:51:15, 445.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 0.6631,           Validation Loss: 0.8967, Duration: 0:07:25.062602, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████████▎          | 36/50 [4:26:12<1:43:51, 445.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 0.6615,           Validation Loss: 0.8948, Duration: 0:07:25.125958, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████          | 37/50 [4:33:37<1:36:28, 445.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 0.6608,           Validation Loss: 0.8955, Duration: 0:07:25.650753, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████▉         | 38/50 [4:41:03<1:29:04, 445.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 0.6597,           Validation Loss: 0.8989, Duration: 0:07:25.684150, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|█████████████████████████████▋        | 39/50 [4:48:28<1:21:39, 445.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 0.6594,           Validation Loss: 0.8934, Duration: 0:07:25.399221, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████▍       | 40/50 [4:55:54<1:14:14, 445.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 0.6581,           Validation Loss: 0.8927, Duration: 0:07:25.706521, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████▏      | 41/50 [5:03:20<1:06:49, 445.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 0.6574,           Validation Loss: 0.8942, Duration: 0:07:25.449537, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████▌      | 42/50 [5:10:45<59:23, 445.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 0.6570,           Validation Loss: 0.8898, Duration: 0:07:25.528631, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████▍     | 43/50 [5:18:11<51:58, 445.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 0.6562,           Validation Loss: 0.8912, Duration: 0:07:25.618892, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|███████████████████████████████████▏    | 44/50 [5:25:37<44:33, 445.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 0.6548,           Validation Loss: 0.8968, Duration: 0:07:25.841174, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████    | 45/50 [5:33:02<37:08, 445.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 0.6538,           Validation Loss: 0.9001, Duration: 0:07:25.877978, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|████████████████████████████████████▊   | 46/50 [5:40:28<29:43, 445.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 0.6537,           Validation Loss: 0.8973, Duration: 0:07:26.060604, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████▌  | 47/50 [5:47:55<22:17, 445.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 0.6525,           Validation Loss: 0.9041, Duration: 0:07:26.366218, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████▍ | 48/50 [5:55:21<14:52, 446.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 0.6517,           Validation Loss: 0.8956, Duration: 0:07:26.109937, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|███████████████████████████████████████▏| 49/50 [6:02:47<07:26, 446.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 0.6516,           Validation Loss: 0.8965, Duration: 0:07:26.192040, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 50/50 [6:10:13<00:00, 444.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 0.6507,           Validation Loss: 0.8954, Duration: 0:07:26.000495, Best Val Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                    train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f65503f8d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.7532\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_val_model_pytorch')\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('best_val_model_pytorch')\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7531903917459294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7210    0.7450    0.7328     53181\n",
      "           1     0.8130    0.8045    0.8087     52523\n",
      "           2     0.7254    0.7074    0.7163     49371\n",
      "\n",
      "    accuracy                         0.7532    155075\n",
      "   macro avg     0.7531    0.7523    0.7526    155075\n",
      "weighted avg     0.7536    0.7532    0.7533    155075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
